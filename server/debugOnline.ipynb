{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCapRasp arena calibration and testing \n",
    "This notebook is a **visual debug tool** to **calibrate and test extrinsics parameters** of the eROBOTICA visual tracking arena. \n",
    "\n",
    "**IMPORTANT NOTES**\n",
    "\n",
    "- The CSV files `camCalib.csv`, `camGround.csv` and `camTest.csv` must be collected via the `calib.py`, `ground.py` and `capture.py` codes, respectively (with the `--save` flag). \n",
    "\n",
    "- Please just change the variables in the noted cells only.\n",
    "\n",
    "- All the non-essential and debug only image plots have been commented, but not removed. Feel free to explore them.\n",
    "\n",
    "- The calibration of intrinsics has already been done with [this repository](https://github.com/debOliveira/myCameraCalibrator) and stored in the file `constants.py`. Please alter the matrices accordingly. \n",
    "\n",
    "- All the mathematical basis of this code can be found on the thesis text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration \n",
    "Just importing libraries and self made functions used in the previous offline arena doodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time,math\n",
    "import numpy as np\n",
    "from constants import cameraMat\n",
    "from cv2 import circle,triangulatePoints,cvtColor,COLOR_GRAY2RGB,computeCorrespondEpilines,putText,FONT_HERSHEY_SIMPLEX,imwrite,Rodrigues\n",
    "from myLib import isCollinear,isEqual,myProjectionPoints,orderCenterCoord,occlusion,getOrderPerEpiline,findPlane,drawlines,findRandT,getTheClosest,myInterpolate,getOtherValidIdx,createNeedsOrder,activateNeedsOrder,popNeedsOrder,estimateFundMatrix_8norm,decomposeEssentialMat,findOtherCamera\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.interpolate import CubicSpline\n",
    "import os\n",
    "from itertools import combinations,permutations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration of extrinsincs\n",
    "\n",
    "The following cell sets up the name of the CSV where the data is stored and the size of the arrays to be read. Alter to the values used with the `calib.py` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "### YOU MAY CHANGE THE VARIABLES BELOW ###\n",
    "##########################################\n",
    "\n",
    "# name (folder/camCalib.csv) where the CSV from calib.py is saved\n",
    "dfCSV = np.genfromtxt('/home/debora/Desktop/MoCapRasp/server/data/camCalib.csv', delimiter=',')\n",
    "verbose = False # verbose flag for reading the data and interpolation \n",
    "nCameras = 4    # number of cameras\n",
    "recTime = 180    # recording time, in seconds\n",
    "step = 1/100    # step of the interpolated DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading coordinates and ordering markers\n",
    "Now, we read each line of the CSV that has the following strings:\n",
    "- *`Ax|Ay|Bx|By|Cx|Cy`*: the x and y undistorted coordinates of each collinear marker A, B or C. \n",
    "- *`time`*: the PTS in seconds from when the image was captured.\n",
    "- *`image number`*: the number of the image in the processing loop at the Raspberry station.\n",
    "- *`index`*: the number the Raspberry station (varies from 0 to `nCameras`).\n",
    "\n",
    "Then we check if there was no processing error in the data (e.g. if there is occlusion between markers or PTS divergion). Finally, we check how many images have been missed comparing to the image number of the last valid image from the stream. Note that we may receive delayed packages between Raspberries, but they come always in order from each stream station.\n",
    "\n",
    "*The markers are ordered using the certainty algorithm proposed in this dissertation.* The timestamp period in which we locate the valid images of each camera's stream is recorded in a separate array and later used for interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating empty arrays\n",
    "counter,i,lastTime = np.zeros(nCameras,dtype=np.int32),0,np.zeros(nCameras,dtype=np.int32)\n",
    "missed,invalid,swap = np.zeros(nCameras,dtype=np.int32),np.zeros(nCameras,dtype=np.int32),np.zeros(nCameras,dtype=np.int32)\n",
    "lastImgNumber = np.zeros(nCameras,dtype=np.int32)\n",
    "certainty,intervals,timeIntervals = np.zeros(nCameras,dtype=np.bool8),[],[]\n",
    "dfOrig,tol = [],0.25\n",
    "for k in range(nCameras):\n",
    "    dfOrig.append([])\n",
    "    intervals.append([])\n",
    "    timeIntervals.append([])\n",
    "\n",
    "# reading the CSV per line\n",
    "while i!=dfCSV.shape[0]:\n",
    "    line = dfCSV[i]\n",
    "    # get data from the line\n",
    "    idx = int(line[8])\n",
    "    undCoord,timeNow,imgNumber = line[0:6].reshape(-1,2),line[6],line[7]\n",
    "    i+=1\n",
    "    # if the timestamp has diverged, discard the image (processing error)\n",
    "    if counter[idx]:\n",
    "        if abs(timeNow-lastTime[idx])>1e9: \n",
    "            if verbose: print('time missmatch')\n",
    "            missed[idx]+=1\n",
    "            invalid[idx]+=1\n",
    "            continue\n",
    "    # check if no image was missed\n",
    "    if imgNumber>lastImgNumber[idx]+1: invalid[idx] = imgNumber-lastImgNumber[idx]\n",
    "    # check collinearity, occlusion and order markers per proximity\n",
    "    if isCollinear(*undCoord) and not isEqual(undCoord,5) and not np.any(undCoord<0):     \n",
    "        if invalid[idx]>=10 or not counter[idx]: \n",
    "            if certainty[idx]:\n",
    "                beg,end = intervals[idx][-1],counter[idx]-1\n",
    "                timeIntervals[idx].append([dfOrig[idx][beg,6],dfOrig[idx][end,6]])\n",
    "                if verbose: print('camera #'+str(idx)+' valid from '+str(round(dfOrig[idx][beg,6]/1e6,2))+'s to '+str(round(dfOrig[idx][end][6]/1e6,2))+'s')\n",
    "            prev,certainty[idx] = [],False\n",
    "            intervals[idx].append(counter[idx])\n",
    "        else:\n",
    "            if not (counter[idx]-1): prev = np.array(dfOrig[idx][0:6]).reshape(-1,2)\n",
    "            else: prev = np.array(dfOrig[idx][-1,0:6]).reshape(-1,2)\n",
    "        undCoord, _ = orderCenterCoord(undCoord,prev)\n",
    "        undCoord = np.array(undCoord)\n",
    "    else: \n",
    "        if verbose: print('not collinear or equal centroids')\n",
    "        missed[idx]+=1\n",
    "        invalid[idx]+=1\n",
    "        continue\n",
    "    # update datasets variables\n",
    "    lastTime[idx],lastImgNumber[idx],invalid[idx] = timeNow,imgNumber,0\n",
    "    if not counter[idx]: dfOrig[idx] = np.hstack((undCoord.reshape(6),timeNow))\n",
    "    else: dfOrig[idx] = np.vstack((dfOrig[idx],np.hstack((undCoord.reshape(6),timeNow))))\n",
    "    counter[idx]+=1\n",
    "    # check if ABC is in order smaller to largest, change if not (but only if certain of the distribution = if at least two images indicate that yes)\n",
    "    if not certainty[idx]:\n",
    "        for [A,B,C] in undCoord.reshape([-1, 3, 2]):\n",
    "            if np.linalg.norm(A-B)/np.linalg.norm(C-B)>(2-tol) and np.linalg.norm(A-B)>20:\n",
    "                swap[idx] += 1\n",
    "                if swap[idx]>2:    \n",
    "                    swap[idx],certainty[idx] = 0,True\n",
    "                    dfOrig[idx][intervals[idx][-1]:counter[idx],0:2],dfOrig[idx][intervals[idx][-1]:counter[idx],4:6] = np.copy(dfOrig[idx][intervals[idx][-1]:counter[idx],4:6]),np.copy(dfOrig[idx][intervals[idx][-1]:counter[idx],0:2])\n",
    "            if np.linalg.norm(C-B)/np.linalg.norm(A-B)>(2-tol) and np.linalg.norm(C-B)>20:  certainty[idx] = True\n",
    "\n",
    "# get last interval validity\n",
    "for idx in range(nCameras):\n",
    "    if not len(dfOrig[idx]): continue\n",
    "    if certainty[idx]:\n",
    "        beg,end = intervals[idx][-1],counter[idx]-1\n",
    "        timeIntervals[idx].append([dfOrig[idx][beg,6],dfOrig[idx][end,6]])    \n",
    "        if verbose: print('camera #'+str(idx)+' valid from '+str(round(dfOrig[idx][beg,6]/1e6,2))+'s to '+str(round(dfOrig[idx][end,6]/1e6,2))+'s')\n",
    "\n",
    "# outcome\n",
    "for i in range(nCameras): \n",
    "    print('  >> camera '+str(i)+': '+str(len(dfOrig[i]))+' valid images, missed '+str(int(missed[i]))+' images')\n",
    "            \n",
    "## debug received centroids  \n",
    "'''for idx in range(nCameras):\n",
    "    os.system('rm pics/cam'+str(idx)+'/*')\n",
    "    for j in range(0,dfOrig[idx].shape[0]):\n",
    "        pts,name,img,k = dfOrig[idx][j,0:6].reshape(-1,2),int(dfOrig[idx][j,6]),np.ones((540,960,3))*255,0\n",
    "        for k in range(0,3):\n",
    "            pt = pts.reshape(-1,2)[k]\n",
    "            center = (int(np.round(pt[0]*16)),int(np.round(pt[1]*16)))\n",
    "            circle(img,center,10,(255,0,0),5,shift=4)\n",
    "            putText(img,str(k),(int(center[0]/16)-25, int(center[1]/16)-25),FONT_HERSHEY_SIMPLEX,0.5,(255,0,0),2) \n",
    "        imwrite('pics/cam'+str(idx+1)+'/'+str(name).zfill(20)+'.jpg',img)''';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the extrinsics parameters\n",
    "\n",
    "Having the centroids ordered, we can interpolate all cameras to a common database and triangulate the markers within the valid time intervals. Then we estimate the fundamental and essential matrices, which can be decomposed to rotation and translation between cameras.\n",
    "\n",
    "It is known that the best calibration result is obtained from cameras that have 90 degrees difference between them. Therefore, we only calibrated sequential pairs (i.g. (0,1), (1,2), (2,3), ...). A bundle adjustment should be added for a larger number of cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating empty arrays\n",
    "rotation,translation,scale,FMatrix,points3D_perPair,ts_perPair,firCentroids,secCentroids = [np.identity(3)],[np.zeros((1,3))],[[1]],[],[],[],[],[]\n",
    "allIdx = [(i,i+1) for i in range(nCameras-1)]           # list of sequential pairs (0,1),(1,2),(2,3)...\n",
    "#allIdx = list(combinations(list(range(nCameras)),2))   # list of all possible pairs\n",
    "\n",
    "# setting up plotting function for epipolar lines\n",
    "from cv2 import line\n",
    "def drawlines(img1,img2,lines,pts1,pts2):\n",
    "    r,c = img1.shape\n",
    "    img1 = cvtColor(img1.astype('float32'),COLOR_GRAY2RGB)\n",
    "    img2 = cvtColor(img2.astype('float32'),COLOR_GRAY2RGB)\n",
    "    listColors = [(0,0,255),(0,255,0),(255,0,0)]\n",
    "    i = 0\n",
    "    for r,pt1,pt2 in zip(lines,pts1,pts2):\n",
    "        color = listColors[i]\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        img1 = line(img1, (x0,y0), (x1,y1), color,1)\n",
    "        img1 = circle(img1,tuple(pt1),5,color,-1)\n",
    "        img2 = circle(img2,tuple(pt2),5,color,-1)\n",
    "        i+=1\n",
    "    return img1,img2\n",
    "\n",
    "# calibration loop for a pair of sequential cameras\n",
    "for [m,n] in allIdx:\n",
    "    # compute valid time intersection for interpolation\n",
    "    intersections = [[max(first[0], second[0]), min(first[1], second[1])]  \n",
    "                        for first in timeIntervals[m] for second in timeIntervals[n]  \n",
    "                        if max(first[0], second[0]) <= min(first[1], second[1])]\n",
    "    # create and fill inteprolation dataset based on the intersection of valid time intervals \n",
    "    dfInterp = np.zeros((int(recTime/step),2*6+1))\n",
    "    dfInterp[:,-1] = np.arange(0,recTime,step)\n",
    "    for [beg,end] in intersections:\n",
    "        for idx in [m,n]:\n",
    "            validIdx = [i for i in range(0,dfOrig[idx].shape[0]) if beg<=dfOrig[idx][i,-1]<=end]\n",
    "            coord,timeNow = dfOrig[idx][validIdx,0:6],dfOrig[idx][validIdx,6]/1e6\n",
    "            if timeNow.shape[0]<=2: continue\n",
    "            lowBound,highBound = math.ceil(timeNow[0]/step),math.floor(timeNow[-1]/step)\n",
    "            if verbose: print('interpolated #'+str(idx+1)+' from '+str(round(lowBound*step,2))+'s to '+str(round(highBound*step,2))+'s')\n",
    "            tNew = np.linspace(lowBound,highBound,int((highBound-lowBound))+1,dtype=np.uint16)\n",
    "            if timeNow.shape[0]<=2: continue\n",
    "            ff = CubicSpline(timeNow,coord,axis=0)\n",
    "            if idx == m: dfInterp[tNew,0:6] = ff(tNew*step)\n",
    "            else: dfInterp[tNew,6:12] = ff(tNew*step)\n",
    "    # get data from the interpolation dataset\n",
    "    dfInterp = np.delete(dfInterp,np.unique([i for i in range(0,dfInterp.shape[0]) for idx in range(2) if not np.any(dfInterp[i][idx*6:idx*6+6])]),axis=0)\n",
    "    if dfInterp.shape[0] < 10: \n",
    "        print('[ERROR] no valid image intersection for cameras '+str(m)+' and '+str(n))\n",
    "        break\n",
    "    centroids1,centroids2 = dfInterp[:,0:6].reshape(-1,2),dfInterp[:,6:12].reshape(-1,2)\n",
    "    print('interpolated '+str(dfInterp.shape[0])+' images between cams '+str(m)+' and '+str(n))\n",
    "    # estimate fundamental and essential matrices \n",
    "    print('[INFO] Computing fundamental and essential matrix between cameras '+str(m)+'-'+str(n))\n",
    "    F,_ = estimateFundMatrix_8norm(np.array(centroids1),np.array(centroids2),verbose=verbose)\n",
    "    E = np.matmul(cameraMat[n].T, np.matmul(F, cameraMat[m]))\n",
    "    if verbose: print(\"\\nEssenc. Mat.\\n\", E.round(4))\n",
    "    # decompose to rotation and translation between cameras\n",
    "    R, t = decomposeEssentialMat(E, cameraMat[m], cameraMat[n], np.array(centroids1), np.array(centroids2))\n",
    "    if np.any(np.isnan(R)): print('no valid rotation matrix')\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"\\nRot. Mat.\\n\", R.round(4))\n",
    "            print(\"\\nTrans. Mat.\\n\", t.round(4))\n",
    "    # create projection matrices and triangulate to compute scale\n",
    "    P1,P2 = np.hstack((cameraMat[m], [[0.], [0.], [0.]])),np.matmul(cameraMat[n], np.hstack((R, t.T)))\n",
    "    projPt1,projPt2 = myProjectionPoints(np.array(centroids1)),myProjectionPoints(np.array(centroids2))\n",
    "    points4d = triangulatePoints(P1.astype(float),P2.astype(float),projPt1.astype(float),projPt2.astype(float))\n",
    "    points3d = (points4d[:3, :]/points4d[3, :]).T\n",
    "    if points3d[0, 2] < 0: points3d = -points3d\n",
    "    tot,L_real_AC,L_real_AB,L_real_BC,L_AC_vec,L_BC_vec,L_AB_vec,k,false_idx,time_idx = 0,15.7,5.35,10.3,[],[],[],0,[],[]\n",
    "    # compute sdt deviation and plot beautiful stuff\n",
    "    for [A, B, C] in points3d.reshape([-1, 3, 3]):\n",
    "        L_rec_AC,L_rec_BC,L_rec_AB = np.linalg.norm(A-C),np.linalg.norm(B-C),np.linalg.norm(A-B)\n",
    "        tot = tot + L_real_AC/L_rec_AC + L_real_BC/L_rec_BC + L_real_AB/L_rec_AB\n",
    "        k = k + 3\n",
    "        L_AC_vec.append(L_rec_AC)\n",
    "        L_BC_vec.append(L_rec_BC)\n",
    "        L_AB_vec.append(L_rec_AB)   \n",
    "    lamb = tot/k\n",
    "    print('\\tScale between real world and triang. point cloud is: ', lamb.round(2))\n",
    "    print('\\tL_AC >> mean = ' + str((np.mean(L_AC_vec)*lamb).round(4)) + \"cm, std. dev = \" + str((np.std(L_AC_vec)*lamb).round(4)) +\n",
    "        \"cm, rms = \" + str((np.sqrt(np.mean(np.square(np.array(L_AC_vec)*lamb-L_real_AC)))).round(4)) + \"cm\")\n",
    "    print('\\tL_AB >> mean = ' + str((np.mean(L_AB_vec)*lamb).round(4)) + \"cm, std. dev = \" + str((np.std(L_AB_vec)*lamb).round(4)) +\n",
    "        \"cm, rms = \" + str((np.sqrt(np.mean(np.square(np.array(L_AB_vec)*lamb-L_real_AB)))).round(4)) + \"cm\")\n",
    "    print('\\tL_BC >> mean = ' + str((np.mean(L_BC_vec)*lamb).round(4)) + \"cm, std. dev = \" + str((np.std(L_BC_vec)*lamb).round(4)) +\n",
    "        \"cm, rms = \" + str((np.sqrt(np.mean(np.square(np.array(L_BC_vec)*lamb-L_real_BC)))).round(4)) + \"cm\")\n",
    "    # debug plot for error before refiment\n",
    "    '''fig = plt.figure(figsize=(10, 6), dpi=200)\n",
    "    L_AC_vec_plot,L_BC_vec_plot,L_AB_vec_plot = np.array(L_AC_vec)*lamb - L_real_AC,np.array(L_BC_vec)*lamb - L_real_BC,np.array(L_AB_vec)*lamb - L_real_AB\n",
    "    plt.plot(dfInterp[:,-1],L_AC_vec_plot, 'o', label=\"AC\")\n",
    "    plt.plot(dfInterp[:,-1],L_BC_vec_plot, 'o', label=\"BC\")\n",
    "    plt.plot(dfInterp[:,-1],L_AB_vec_plot, 'o', label=\"AB\")\n",
    "    plt.axhline(y=0.0, color='r', linestyle='-',linewidth=5)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"time (seconds)\",fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(\"Deviation to real value (cm)\",fontsize=14,fontweight='bold')\n",
    "    plt.legend()\n",
    "    ax = fig.axes\n",
    "    ax[0].minorticks_on()\n",
    "    plt.grid(which='both')\n",
    "    plt.xlim(0,recTime)\n",
    "    plt.rc('xtick',labelsize=14)\n",
    "    plt.rc('ytick',labelsize=14)\n",
    "    plt.draw()\n",
    "    plt.show()'''\n",
    "    # getting indexes of images where the AC markers are further than 1% of the real distance\n",
    "    points3d_new,i,k= points3d*lamb,0,0\n",
    "    for [A, B, C] in points3d_new.reshape([-1, 3, 3]):\n",
    "        L_reconst = np.sqrt(np.sum((A-C)**2, axis=0))\n",
    "        valid = abs(L_real_AC-L_reconst)/L_real_AC < 0.01\n",
    "        if not valid: \n",
    "            i = i + 1\n",
    "            false_idx.extend((k,k+1,k+2))\n",
    "            time_idx.append(int(k/3))\n",
    "        k+=3\n",
    "    print(\"\\tImages distant more than 1% from the real value = \" + str(i)+'/'+str(int(points3d.shape[0]/3)))\n",
    "    # deleting points and refining estimation of the fundamental and essential matrices\n",
    "    print(\"[INFO] Refining fundamental matrix estimation\")\n",
    "    centroids1,centroids2,dfInterp=np.delete(centroids1,false_idx,axis=0),np.delete(centroids2,false_idx,axis=0),np.delete(dfInterp,time_idx,axis=0)\n",
    "    F,_ = estimateFundMatrix_8norm(np.array(centroids1),np.array(centroids2),verbose = 0)\n",
    "    E = np.matmul(cameraMat[n].T, np.matmul(F, cameraMat[m]))\n",
    "    if verbose: print(\"\\nEssenc. Mat.\\n\", E.round(4))\n",
    "    # decompose to rotation and translation between cameras\n",
    "    R, t = decomposeEssentialMat(E, cameraMat[m], cameraMat[n], np.array(centroids1), np.array(centroids2))\n",
    "    if np.any(np.isnan(R)): print('no valid rotation matrix')\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"\\nRot. Mat.\\n\", R.round(4))\n",
    "            print(\"\\nTrans. Mat.\\n\", t.round(4))\n",
    "    P1,P2 = np.hstack((cameraMat[m], [[0.], [0.], [0.]])),np.matmul(cameraMat[n], np.hstack((R, t.T)))\n",
    "    projPt1,projPt2 = myProjectionPoints(np.array(centroids1)),myProjectionPoints(np.array(centroids2))\n",
    "    points4d = triangulatePoints(P1.astype(float),P2.astype(float),projPt1.astype(float),projPt2.astype(float))\n",
    "    points3d = (points4d[:3, :]/points4d[3, :]).T\n",
    "    if points3d[0, 2] < 0: points3d = -points3d\n",
    "    tot,L_AC_vec,L_BC_vec,L_AB_vec,k,false_idx = 0,[],[],[],0,[]\n",
    "    # compute sdt deviation and plot beautiful stuff\n",
    "    for [A, B, C] in points3d.reshape([-1, 3, 3]):\n",
    "        L_rec_AC,L_rec_BC,L_rec_AB = np.linalg.norm(A-C),np.linalg.norm(B-C),np.linalg.norm(A-B)\n",
    "        tot = tot + L_real_AC/L_rec_AC + L_real_BC/L_rec_BC + L_real_AB/L_rec_AB\n",
    "        k = k + 3\n",
    "        L_AC_vec.append(L_rec_AC)\n",
    "        L_BC_vec.append(L_rec_BC)\n",
    "        L_AB_vec.append(L_rec_AB)   \n",
    "    lamb = tot/k\n",
    "    print('\\tScale between real world and triang. point cloud is: ', lamb.round(2))\n",
    "    print('\\tL_AC >> mean = ' + str((np.mean(L_AC_vec)*lamb).round(4)) + \"cm, std. dev = \" + str((np.std(L_AC_vec)*lamb).round(4)) +\n",
    "        \"cm, rms = \" + str((np.sqrt(np.mean(np.square(np.array(L_AC_vec)*lamb-L_real_AC)))).round(4)) + \"cm\")\n",
    "    print('\\tL_AB >> mean = ' + str((np.mean(L_AB_vec)*lamb).round(4)) + \"cm, std. dev = \" + str((np.std(L_AB_vec)*lamb).round(4)) +\n",
    "        \"cm, rms = \" + str((np.sqrt(np.mean(np.square(np.array(L_AB_vec)*lamb-L_real_AB)))).round(4)) + \"cm\")\n",
    "    print('\\tL_BC >> mean = ' + str((np.mean(L_BC_vec)*lamb).round(4)) + \"cm, std. dev = \" + str((np.std(L_BC_vec)*lamb).round(4)) +\n",
    "        \"cm, rms = \" + str((np.sqrt(np.mean(np.square(np.array(L_BC_vec)*lamb-L_real_BC)))).round(4)) + \"cm\")\n",
    "    # debug plot for error after refiment\n",
    "    fig = plt.figure(figsize=(10, 6), dpi=100)\n",
    "    L_AC_vec_plot,L_BC_vec_plot,L_AB_vec_plot = np.array(L_AC_vec)*lamb - L_real_AC,np.array(L_BC_vec)*lamb - L_real_BC,np.array(L_AB_vec)*lamb - L_real_AB\n",
    "    plt.plot(dfInterp[:,-1],L_AC_vec_plot, 'o', label=\"AC\")\n",
    "    plt.plot(dfInterp[:,-1],L_BC_vec_plot, 'o', label=\"BC\")\n",
    "    plt.plot(dfInterp[:,-1],L_AB_vec_plot, 'o', label=\"AB\")\n",
    "    plt.axhline(y=0.0, color='r', linestyle='-',linewidth=5)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"time (seconds)\",fontsize=14, fontweight='bold')\n",
    "    plt.ylabel(\"Deviation to real value (cm)\",fontsize=14,fontweight='bold')\n",
    "    plt.legend()\n",
    "    ax = fig.axes\n",
    "    ax[0].minorticks_on()\n",
    "    plt.grid(which='both')\n",
    "    plt.xlim(0,recTime)\n",
    "    plt.rc('xtick',labelsize=14)\n",
    "    plt.rc('ytick',labelsize=14)\n",
    "    plt.draw()\n",
    "    plt.show()\n",
    "    # saving extrinsics parameters to later use\n",
    "    translation.append(t)\n",
    "    rotation.append(R)\n",
    "    scale.append([lamb])\n",
    "    FMatrix.append(F)\n",
    "    points3D_perPair.append(points3d)\n",
    "    ts_perPair.append(dfInterp[:,-1])\n",
    "    firCentroids.append(centroids1)\n",
    "    secCentroids.append(centroids2)\n",
    "    # epipolar lines plot  \n",
    "    '''img1,img2,n = np.ones((720,960))*255,np.ones((720,960))*255,0\n",
    "    pts1,pts2 = np.int32(centroids1[n:n+3].reshape(-1,2)),np.int32(centroids2[n:n+3].reshape(-1,2))\n",
    "    lines1 = computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n",
    "    lines1 = lines1.reshape(-1,3)\n",
    "    img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)\n",
    "    lines2 = computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n",
    "    lines2 = lines2.reshape(-1,3)\n",
    "    img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)\n",
    "    plt.figure(figsize=(20, 16),dpi=100)\n",
    "    plt.subplot(121),plt.imshow(img5.astype(np.uint8))\n",
    "    plt.subplot(122),plt.imshow(img3.astype(np.uint8))\n",
    "    plt.show()'''\n",
    "    print('--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update reference to the 0th camera\n",
    "\n",
    "With the rotation and translation in scale between cameras, we have to compound the rigid body transformations and obtain the pose of each camera in relation to the 0th camera. The triangulated 3D points must also be rotated and translated in reference to the world origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 3D plot variables\n",
    "fig = plt.figure(figsize=(8, 8),dpi=100)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlim(-1, 4)\n",
    "ax.set_zlim(-6, 0)\n",
    "ax.set_ylim(-1, 4)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Z')\n",
    "ax.set_zlabel('Y')\n",
    "ax.set_xlabel('X', fontweight='bold',labelpad=15)\n",
    "ax.set_ylabel('Z', fontweight='bold',labelpad=15)\n",
    "ax.set_zlabel('Y', fontweight='bold',labelpad=5)\n",
    "cmhot = plt.get_cmap(\"jet\")\n",
    "ax.view_init(elev=30, azim=-50) \n",
    "plt.gca().invert_zaxis()\n",
    "ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([1., 1., .5, 1.]))\n",
    "colours = [['fuchsia','plum'],['darkorange','gold'],['limegreen','greenyellow'],['blue','lightsteelblue']]\n",
    "\n",
    "# initializing arrays\n",
    "allPts3d,projMat = [],[]\n",
    "dfTriang = np.zeros((int(recTime/step),(nCameras-1)*4*3+1))\n",
    "dfTriang[:,-1] = np.arange(0,recTime,step)\n",
    "\n",
    "# getting coordinates from each camera and 3D points in relation to the 0th camera\n",
    "for j in range(nCameras):\n",
    "    # initialize initial values of the projection matrices\n",
    "    x,y,z= np.array([1, 0, 0, 0]), np.array([0, 1, 0, 0]),np.array([0, 0, 1, 0])\n",
    "    P_new = np.vstack((np.hstack((np.identity(3),np.zeros((3,1)))),np.hstack((np.zeros((3)),1))))\n",
    "    # iterate over the previous cameras to find the relation to the 0th camera\n",
    "    # e.g. 3 -> 2 -> 1 -> 0\n",
    "    for i in np.flip(range(j+1)):\n",
    "        t,R,lamb = np.array(translation[i][0]).reshape(-1,3),np.array(rotation[i]),scale[i]\n",
    "        t_new = np.matmul(-t, R).reshape(-1,3)*lamb/100\n",
    "        P = np.vstack((np.hstack((R.T,t_new.T)),np.hstack((np.zeros((3)),1))))\n",
    "        P_new = np.matmul(P,P_new)\n",
    "    # save new projection matrix\n",
    "    projMat.append(P_new)\n",
    "    # plot camera pose\n",
    "    x,y,z = np.matmul(P_new,x),np.matmul(P_new,y),np.matmul(P_new,z)\n",
    "    o = np.matmul(P_new,[[0.],[0.],[0.],[1]]).ravel()\n",
    "    ax.quiver(o[0], o[2], o[1], x[0], x[2], x[1], arrow_length_ratio=0.1, edgecolors=\"r\", label='X axis')\n",
    "    ax.quiver(o[0], o[2], o[1], y[0], y[2], y[1], arrow_length_ratio=0.1, edgecolors=\"b\", label='Y axis')\n",
    "    ax.quiver(o[0], o[2], o[1], z[0], z[2], z[1], arrow_length_ratio=0.1, edgecolors=\"g\", label='Z axis')\n",
    "    ax.scatter(o[0], o[2], o[1], s=50, edgecolor=colours[j][0], facecolor=colours[j][1], linewidth=2,  label = 'Camera '+str(j))\n",
    "    # save triangulated 3D points in relation to the 0th camera\n",
    "    if j<(nCameras-1):\n",
    "        points3d = np.hstack((points3D_perPair[j]*scale[j+1][0]/100,np.ones((points3D_perPair[j].shape[0],1)))).T\n",
    "        points3d = np.matmul(P_new,points3d)\n",
    "        dfTriang[np.array(ts_perPair[j]*(1/step)).astype(int),j*12:(j+1)*12] = points3d.T.reshape(-1,12)\n",
    "        ax.scatter(points3d[0], points3d[2], points3d[1], s=50, c=points3d[2], cmap=cmhot)\n",
    "        if not len(allPts3d): allPts3d = points3d.copy()\n",
    "        else: allPts3d = np.hstack((allPts3d,points3d.copy()))\n",
    "\n",
    "# final plot commands\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),ncol=3,loc ='center',edgecolor='silver', bbox_to_anchor=(0.5, 0.8))\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global bundle adjustment\n",
    "\n",
    "For a larger number of cameras, you may use optimzation to minimize the reprojection error. It would be ideal to have the same number of points between each camera pair, which could be achieved using clusterization or a weighted regression. Thus, this is a non-linear weighted sparse least squares problem. A solution was derived from [this `scipy` project](https://scipy-cookbook.readthedocs.io/items/bundle_adjustment.html).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from scipy.sparse import lil_matrix\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# Computing the 2D reprojection from a 3D point >> x = PX\n",
    "def reproject(points3d,cameraParams):\n",
    "    camCoef,rod,t,R  = cameraParams[:,0:4],cameraParams[:,4:7].reshape(-1,3,1),cameraParams[:,7:10].reshape(-1,3,1),[]\n",
    "    for r in rod: R.append(Rodrigues(r)[0])\n",
    "    R = np.array(R).reshape(-1,3,3)\n",
    "    nPts = camCoef.shape[0]\n",
    "    K = np.transpose(np.array([[camCoef[:,0],np.zeros(nPts),camCoef[:,2]],\n",
    "                  [np.zeros(nPts),camCoef[:,1],camCoef[:,3]], \n",
    "                  [np.zeros(nPts),np.zeros(nPts),np.ones(nPts)]]),(2,0,1)) \n",
    "    P = np.matmul(K,np.dstack((R, t)))\n",
    "    newPts3D = np.transpose(np.hstack((points3d,np.ones((points3d.shape[0],1)))).reshape(-1,1,4),(0,2,1))\n",
    "    newPts = np.matmul(P,newPts3D)\n",
    "    pts2D = newPts[:,0:2,:]/newPts[:,2,:].reshape(-1,1,newPts.shape[-1])\n",
    "    return np.transpose(pts2D,(0,2,1)).reshape(-1,2)\n",
    "\n",
    "# residual computation formula >> x_reprojected - x_measured\n",
    "def reprojectionError(params,nCameras,points_2d,cameraIdx,pointIdx,weights):\n",
    "    cameraParams = params[:nCameras*10].reshape(-1, 10)\n",
    "    points_3d = params[nCameras*10:].reshape(-1, 3)\n",
    "    points_proj = reproject(points_3d[pointIdx.astype(int)], cameraParams[cameraIdx.astype(int)])\n",
    "    return np.multiply(weights,points_proj - points_2d).ravel()\n",
    "\n",
    "# sparse matrix (the 0th camera stays at the origin)\n",
    "def bundle_adjustment_sparsity(nCameras,nPts,camIdx,pointIdx):\n",
    "    m = camIdx.size*2\n",
    "    n = nCameras*10+nPts*3\n",
    "    A = lil_matrix((m, n), dtype=int)\n",
    "    i = np.arange(camIdx.size)\n",
    "    for s in range(4,10):\n",
    "        A[2*i[int(camIdx.size/2):],10+s] = 1\n",
    "        A[2*i[int(camIdx.size/2):]+1,10+s] = 1\n",
    "    for s in range(3):\n",
    "        A[2*i,nCameras*10+pointIdx*3+s] = 1\n",
    "        A[2*i+1,nCameras*10+pointIdx*3+s] = 1\n",
    "    A[:,0:10] = 0\n",
    "    return A     \n",
    "\n",
    "# initiating arrays\n",
    "cameraParams,points3d,points2d,cameraIdx,pointIdx,weights = [],[],[],[],[],[]\n",
    "# setting camera parameters to shape using rodrigues vectors\n",
    "for i in range(nCameras): \n",
    "    K = cameraMat[i]\n",
    "    P = projMat[i].copy()    \n",
    "    R = P[0:3,0:3].T\n",
    "    lamb = np.linalg.norm(P[0:3,3])*100\n",
    "    if not lamb: t = np.matmul(-np.copy(P[0:3,3]),R.T).reshape(-1,3)\n",
    "    else: t = np.matmul(-np.copy(P[0:3,3]*100/lamb),R.T).reshape(-1,3)*lamb/100\n",
    "    #if i==1: P = np.matmul(K,np.hstack((R, t.T)))\n",
    "    if not len(cameraParams): cameraParams=np.hstack((np.array([K[0][0],K[1][1],K[0][2],K[1][2]]).reshape(-1,4),Rodrigues(R)[0].reshape(-1,3),t.reshape(-1,3)))\n",
    "    else: cameraParams=np.vstack((cameraParams,np.hstack((np.array([K[0][0],K[1][1],K[0][2],K[1][2]]).reshape(-1,4),Rodrigues(R)[0].reshape(-1,3),t.reshape(-1,3)))))\n",
    "x = np.hstack((cameraParams.ravel(), allPts3d[0:3].T.ravel()))\n",
    "# setting indexes and weight variables to shape\n",
    "for i in range(len(allIdx)):\n",
    "    new2dPts = np.vstack((firCentroids[i],secCentroids[i]))\n",
    "    [m,n]=allIdx[i]\n",
    "    if not len(points2d): \n",
    "        points2d = new2dPts.copy()\n",
    "        cameraIdx = np.hstack((np.ones(firCentroids[i].shape[0])*m,np.ones(secCentroids[i].shape[0])*n))\n",
    "        weights = np.ones(firCentroids[i].shape[0]*2)/(firCentroids[i].shape[0]*2)\n",
    "        pointIdx = np.hstack(([i for i in range(firCentroids[i].shape[0])],[i for i in range(secCentroids[i].shape[0])]))\n",
    "    else: \n",
    "        points2d = np.vstack((points2d,new2dPts.copy()))\n",
    "        cameraIdx = np.hstack((cameraIdx,np.ones(firCentroids[i].shape[0])*m,np.ones(secCentroids[i].shape[0])*n))\n",
    "        offset = pointIdx[-1]+1\n",
    "        weights = np.hstack((weights,np.ones(firCentroids[i].shape[0]*2)/(firCentroids[i].shape[0]*2)))\n",
    "        pointIdx = np.hstack((pointIdx,np.hstack(([i for i in range(offset,offset+firCentroids[i].shape[0])],\n",
    "                                                    [i for i in range(offset,offset+secCentroids[i].shape[0])]))))\n",
    "weights = (weights*cameraIdx.shape[0]).reshape(-1,1)\n",
    "# Least squares (but not weighted)\n",
    "r = reprojectionError(x,nCameras,points2d,cameraIdx,pointIdx,np.ones_like(weights))\n",
    "A = bundle_adjustment_sparsity(nCameras,allPts3d.shape[1],cameraIdx,pointIdx)\n",
    "res = least_squares(reprojectionError, x, jac_sparsity=A, verbose=0, x_scale='jac', ftol=1e-6, method='trf',\n",
    "                    args=(nCameras,points2d,cameraIdx,pointIdx,np.ones_like(weights)))\n",
    "\n",
    "# plot debug \n",
    "# plt.plot(r,label='initial residue')                    \n",
    "# plt.plot(res.fun,label='optimized residue')\n",
    "print('Before optimization reprojection error (in pixels): ')\n",
    "print('\\tMean:',r.mean())\n",
    "print('\\tStd. dev. :',r.std())\n",
    "print('\\tMin:',r.min())\n",
    "print('\\tMax:',r.max())\n",
    "r = reprojectionError(res.x,nCameras,points2d,cameraIdx,pointIdx,np.ones_like(weights))\n",
    "print('After optimization reprojection error (in pixels): ')\n",
    "print('\\tMean:',r.mean())\n",
    "print('\\tStd. dev. :',r.std())\n",
    "print('\\tMin:',r.min())\n",
    "print('\\tMax:',r.max())''';"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration of ground plane\n",
    "\n",
    "The following cell sets up the name of the CSV where the data is stored and the size of the arrays to be read. Alter to the values used with the `ground.py` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "### YOU MAY CHANGE THE VARIABLES BELOW ###\n",
    "##########################################\n",
    "\n",
    "# name (folder/camGround.csv) where the CSV from ground.py is saved\n",
    "dfCSV = np.genfromtxt('/home/debora/Desktop/MoCapRasp/server/data/camGround.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centroid ordering\n",
    "\n",
    "As we already know the fundamental matrix between the cameras 0 and 1, we use the epipolar line approach to order the centroids. Because the wand is still, we do not need to interpolate the points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate variables\n",
    "counter,i,lastTime = np.zeros(nCameras,dtype=np.int32),0,np.zeros(nCameras,dtype=np.int32)\n",
    "\n",
    "# read from CSV\n",
    "while i!=dfCSV.shape[0]:\n",
    "    # get data from the line\n",
    "    line = dfCSV[i]\n",
    "    idx = int(line[8])\n",
    "    undCoord,timeNow,imgNumber = line[0:6].reshape(-1,2),line[6],line[7]\n",
    "    # save points\n",
    "    if not counter[idx]: dfOrig[idx] = np.hstack((undCoord.reshape(6),timeNow))\n",
    "    # update datasets variables\n",
    "    i+=1\n",
    "    counter[idx]+=1\n",
    "    # do I have enough points? break if yes\n",
    "    if np.all(counter>0): break\n",
    "\n",
    "# order centroids\n",
    "for j in range(nCameras-1):\n",
    "    # collect extrinsics from calibration between camera 0 and 1\n",
    "    F = FMatrix[j]\n",
    "    R,t,lamb = rotation[j+1],translation[j+1].reshape(-1,3),scale[j+1]\n",
    "    # order centroids per epipolar line\n",
    "    pts1,pts2 = dfOrig[j][0:6].reshape(-1,2),dfOrig[j+1][0:6].reshape(-1,2)\n",
    "    orderSecondFrame = getOrderPerEpiline(pts1,pts2,3,np.copy(F))\n",
    "    pts2 = np.copy(pts2[orderSecondFrame])\n",
    "    # save dataset\n",
    "    dfOrig[j+1][0:6] = pts2.copy().ravel()\n",
    "    # plot corresponding centroids \n",
    "    '''pts1,pts2 = np.int32(pts1),np.int32(pts2)\n",
    "    img1,img2 = np.zeros((720,960)),np.zeros((720,960))\n",
    "    lines1 = computeCorrespondEpilines(pts2.reshape(-1,1,2), 2,F)\n",
    "    lines1 = lines1.reshape(-1,3)\n",
    "    img5,_ = drawlines(img1,img2,lines1,pts1,pts2)\n",
    "    lines2 = computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,F)\n",
    "    lines2 = lines2.reshape(-1,3)\n",
    "    img3,_ = drawlines(img2,img1,lines2,pts2,pts1)\n",
    "    plt.figure(figsize=(8, 6),dpi=100)\n",
    "    plt.imshow(img5.astype(np.uint8)) \n",
    "    plt.axis('off') \n",
    "    plt.show()\n",
    "    plt.figure(figsize=(8, 6),dpi=100)\n",
    "    plt.imshow(img3.astype(np.uint8))\n",
    "    plt.axis('off') \n",
    "    plt.show()''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangulation and plane estimation\n",
    "\n",
    "We use the ordered centroids and triangulate using the calibrated extrinsics. We may then find the plane that passes trought the three triangulated points and the rigid body transformation to make it equal to the ground XZ plane. \n",
    "\n",
    "Firstly, we translate the plane `d/b` units to match the Y axis origin. After, we rotate it to meet as close as possible the plane `y = 0`. Finally we displaced all cameras so the 0th camera occupies `[0,h,0]`, for `h` the height of the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangulate ordered centroids from the first pair\n",
    "pts1,pts2 = np.copy(dfOrig[0][0:6].reshape(-1,2)),np.copy(dfOrig[1][0:6].reshape(-1,2))\n",
    "R,t,lamb = rotation[1],translation[1].reshape(-1,3),scale[1]\n",
    "P1,P2 = np.hstack((cameraMat[0], [[0.], [0.], [0.]])),np.matmul(cameraMat[1], np.hstack((R, t.T)))\n",
    "projPt1,projPt2 = myProjectionPoints(np.array(pts1)),myProjectionPoints(np.array(pts2))\n",
    "points4d = triangulatePoints(P1.astype(float),P2.astype(float),projPt1.astype(float),projPt2.astype(float))\n",
    "points3d = (points4d[:3, :]/points4d[3, :]).T\n",
    "if points3d[0, 2] < 0: points3d = -points3d\n",
    "points3d = points3d*lamb/100\n",
    "\n",
    "# get ground plane coefficients\n",
    "plane = findPlane(points3d[0],points3d[1],points3d[2])\n",
    "if np.any(plane[0:3]<0): plane = findPlane(points3d[0],points3d[2],points3d[1])\n",
    "[a,b,c,d]=plane\n",
    "# get the orthonogal vector to the plane\n",
    "v,k=np.array([a,b,c]),np.array([0,1,0])\n",
    "# compute the angle between the plane and the y axis\n",
    "cosPhi = np.dot(v,k)/(np.linalg.norm(v)*np.linalg.norm(k))\n",
    "# compute the versors\n",
    "[u1,u2,u3] = np.cross(v,k)/np.linalg.norm(np.cross(v,k))\n",
    "# get the rotation matrix and new ground plane coefficients\n",
    "sinPhi = np.sqrt(1-pow(cosPhi,2))\n",
    "R_plane = np.array([\n",
    "        [cosPhi+u1*u1*(1-cosPhi),u1*u2*(1-cosPhi)-u3*sinPhi,u2*sinPhi+u1*u3*(1-cosPhi)],\n",
    "        [u1*u2*(1-cosPhi)+u3*sinPhi,cosPhi+u2*u2*(1-cosPhi),u2*u3*(1-cosPhi)-u1*sinPhi],\n",
    "        [u1*u3*(1-cosPhi)-u2*sinPhi,u2*u3*(1-cosPhi)+u1*sinPhi,cosPhi+u3*u3*(1-cosPhi)]])\n",
    "[A,B,C] = np.matmul(R_plane,np.array([a,b,c]).T)\n",
    "newPlane = np.array([A,B,C])\n",
    "\n",
    "# setting 3D plot variables\n",
    "fig = plt.figure(figsize=(8, 8),dpi=100)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlim(-1, 4)\n",
    "ax.set_zlim(-6, 0)\n",
    "ax.set_ylim(-1, 4)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Z')\n",
    "ax.set_zlabel('Y')\n",
    "ax.set_xlabel('X', fontweight='bold',labelpad=15)\n",
    "ax.set_ylabel('Z', fontweight='bold',labelpad=15)\n",
    "ax.set_zlabel('Y', fontweight='bold',labelpad=5)\n",
    "cmhot = plt.get_cmap(\"jet\")\n",
    "ax.view_init(elev=30, azim=-50) \n",
    "plt.gca().invert_zaxis()\n",
    "ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([1., 1., .5, 1.]))\n",
    "colours = [['fuchsia','plum'],['darkorange','gold'],['limegreen','greenyellow'],['blue','lightsteelblue']]\n",
    "\n",
    "# initializing arrays\n",
    "zDisplacement = 0\n",
    "P_plane = np.vstack((np.hstack((R_plane,np.array([0,0,0]).reshape(3,-1))),np.hstack((np.zeros((3)),1))))\n",
    "\n",
    "# plot each camera translated and rotated to meet the ground plane\n",
    "for j in range(nCameras):\n",
    "    o = np.matmul(projMat[j],[[0.],[0],[0.],[1]]).ravel()\n",
    "    o+= [0,+d/b,0,0]\n",
    "    o = np.matmul(P_plane,o).ravel()\n",
    "    if not j: zDisplacement = o[2]\n",
    "    o+= [0,0,-zDisplacement,0]\n",
    "    x,y,z= np.array([1, 0, 0, 0]), np.array([0, 1, 0, 0]),np.array([0, 0, 1, 0])\n",
    "    x,y,z = np.matmul(projMat[j],x),np.matmul(projMat[j],y),np.matmul(projMat[j],z)\n",
    "    x,y,z = np.matmul(P_plane,x),np.matmul(P_plane,y),np.matmul(P_plane,z)\n",
    "    ax.quiver(o[0], o[2], o[1], x[0], x[2], x[1], arrow_length_ratio=0.1, edgecolors=\"r\", label='X axis')\n",
    "    ax.quiver(o[0], o[2], o[1], y[0], y[2], y[1], arrow_length_ratio=0.1, edgecolors=\"b\", label='Y axis')\n",
    "    ax.quiver(o[0], o[2], o[1], z[0], z[2], z[1], arrow_length_ratio=0.1, edgecolors=\"g\", label='Z axis')\n",
    "    ax.scatter(o[0], o[2], o[1], s=50, edgecolor=colours[j][0], facecolor=colours[j][1], linewidth=2,  label = 'Camera '+str(j))\n",
    "    \n",
    "# plot the ground plane\n",
    "x,z = np.linspace(-1,1,30),np.linspace(3,5,10)\n",
    "X,Z = np.meshgrid(x,z)\n",
    "Y=(-newPlane[0]*X -newPlane[2]*Z)/newPlane[1]\n",
    "surf = ax.plot_surface(X,Z-zDisplacement,Y,color='b',alpha=.15,label=\"Wand's plane\")\n",
    "surf._facecolors2d = surf._facecolor3d\n",
    "surf._edgecolors2d = surf._edgecolor3d\n",
    "# plot markers\n",
    "points3d = np.hstack((points3d,np.ones((points3d.shape[0],1))))\n",
    "points3d+= [0,d/b,0,0]\n",
    "points3d = np.matmul(P_plane,points3d.T).T\n",
    "points3d+= [0,0,-zDisplacement,0]\n",
    "points3d = points3d.T\n",
    "ax.scatter(points3d[0], points3d[2], points3d[1], s=50, c=points3d[2], cmap=cmhot, label= 'Markers')\n",
    "\n",
    "# axis setup and plot variables\n",
    "first3Dpoints = points3d.copy()\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),ncol=3,loc ='center',edgecolor='silver', bbox_to_anchor=(0.5, 0.8))\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction matrices\n",
    "\n",
    "Since **there are errors in the focal distance** calibration, there will be errors when matching the clouds from different pairs of camera. But we can compute the rotation and translation from each point cloud to the point cloud of the pair 0-1. \n",
    "\n",
    "**I opted not to use it and really see the calibration errors between the pairs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# setting 3D plot variables\n",
    "fig = plt.figure(figsize=(8, 8),dpi=100)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlim(0.2, 0.8)\n",
    "ax.set_zlim(-6, 0)\n",
    "ax.set_ylim(2.8,3.2)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Z')\n",
    "ax.set_zlabel('Y')\n",
    "ax.set_xlabel('X', fontweight='bold',labelpad=15)\n",
    "ax.set_ylabel('Z', fontweight='bold',labelpad=15)\n",
    "ax.set_zlabel('Y', fontweight='bold',labelpad=5)\n",
    "cmhot = plt.get_cmap(\"jet\")\n",
    "ax.view_init(elev=30, azim=-50) \n",
    "plt.gca().invert_zaxis()\n",
    "ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([1., 1., .5, 1.]))\n",
    "colours = [['fuchsia','plum'],['darkorange','gold'],['limegreen','greenyellow'],['blue','lightsteelblue']]\n",
    "\n",
    "# plot each camera translated and rotated to meet the ground plane\n",
    "for j in range(nCameras):\n",
    "    o = np.matmul(projMat[j],[[0.],[0],[0.],[1]]).ravel()\n",
    "    o+= [0,+d/b,0,0]\n",
    "    o = np.matmul(P_plane,o).ravel()\n",
    "    o+= [0,0,-zDisplacement,0]\n",
    "    x,y,z= np.array([1, 0, 0, 0]), np.array([0, 1, 0, 0]),np.array([0, 0, 1, 0])\n",
    "    x,y,z = np.matmul(projMat[j],x),np.matmul(projMat[j],y),np.matmul(projMat[j],z)\n",
    "    x,y,z = np.matmul(P_plane,x),np.matmul(P_plane,y),np.matmul(P_plane,z)\n",
    "    ax.quiver(o[0], o[2], o[1], x[0], x[2], x[1], arrow_length_ratio=0.1, edgecolors=\"r\", label='X axis')\n",
    "    ax.quiver(o[0], o[2], o[1], y[0], y[2], y[1], arrow_length_ratio=0.1, edgecolors=\"b\", label='Y axis')\n",
    "    ax.quiver(o[0], o[2], o[1], z[0], z[2], z[1], arrow_length_ratio=0.1, edgecolors=\"g\", label='Z axis')\n",
    "    ax.scatter(o[0], o[2], o[1], s=50, edgecolor=colours[j][0], facecolor=colours[j][1], linewidth=2,  label = 'Camera '+str(j))\n",
    "\n",
    "# plot the 3d points of the first camera\n",
    "ax.scatter(first3Dpoints[0], first3Dpoints[2], first3Dpoints[1], s=50, c=first3Dpoints[2], cmap=cmhot, label= 'Markers')\n",
    "correcMat = []\n",
    "\n",
    "# plot the matching 3d points for the other cameras\n",
    "for j in range(1,nCameras-1):\n",
    "    # get data\n",
    "    pts1,pts2 = dfOrig[j][0:6].reshape(-1,2),dfOrig[j+1][0:6].reshape(-1,2)\n",
    "    F = FMatrix[j]\n",
    "    R,t,lamb = rotation[j+1],translation[j+1].reshape(-1,3),scale[j+1]\n",
    "    P1,P2 = np.hstack((cameraMat[j], [[0.], [0.], [0.]])),np.matmul(cameraMat[j+1], np.hstack((R, t.T)))\n",
    "    projPt1,projPt2 = myProjectionPoints(np.array(pts1)),myProjectionPoints(np.array(pts2))\n",
    "    # triangulate points\n",
    "    points4d = triangulatePoints(P1.astype(float),P2.astype(float),projPt1.astype(float),projPt2.astype(float))\n",
    "    points3d = (points4d[:3, :]/points4d[3, :]).T\n",
    "    if points3d[0, 2] < 0: points3d = -points3d\n",
    "    # displacement \n",
    "    points3d = np.hstack((points3d*scale[j+1][0]/100,np.ones((points3d.shape[0],1)))).T\n",
    "    points3d = np.matmul(projMat[j],points3d).T\n",
    "    points3d+= [0,d/b,0,0]\n",
    "    points3d = np.matmul(P_plane,points3d.T).T\n",
    "    points3d+= [0,0,-zDisplacement,0]\n",
    "    # compute correction amtrix\n",
    "    ptA,ptB = np.copy(points3d.T[0:3]),np.copy(first3Dpoints[0:3])\n",
    "    R,t = findRandT(ptA,ptB)\n",
    "    P = np.vstack((np.hstack((R,t.reshape(-1,1))),np.hstack((np.zeros((3)),1))))\n",
    "    # save projection matrix\n",
    "    correcMat.append(P)\n",
    "    # rotate points and plot\n",
    "    points3d = np.matmul(P,points3d.T).T\n",
    "    points3d = points3d.T\n",
    "    print(np.linalg.norm(points3d - first3Dpoints,axis=0)*100)\n",
    "    ax.scatter(points3d[0], points3d[2], points3d[1], s=50, c=points3d[2], cmap=cmhot, label= 'Markers')\n",
    "\n",
    "# plot the ground plane\n",
    "#x,z = np.linspace(-1,1,30),np.linspace(3,5,10)\n",
    "#X,Z = np.meshgrid(x,z)\n",
    "#Y=(-newPlane[0]*X -newPlane[2]*Z)/newPlane[1]\n",
    "#surf = ax.plot_surface(X,Z-zDisplacement,Y,color='b',alpha=.15,label=\"Wand's plane\")\n",
    "#surf._facecolors2d = surf._facecolor3d\n",
    "#surf._edgecolors2d = surf._edgecolor3d\n",
    "\n",
    "# axis setup and plot variables\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),ncol=3,loc ='center',edgecolor='silver', bbox_to_anchor=(0.5, 0.8))\n",
    "plt.draw()\n",
    "plt.show()''';"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing flight\n",
    "\n",
    "The following cell sets up the name of the CSV where the data is stored and the size of the arrays to be read. Alter to the values used with the `capture.py` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "### YOU MAY CHANGE THE VARIABLES BELOW ###\n",
    "##########################################\n",
    "\n",
    "# name (folder/camTest.csv) where the CSV from capture.py is saved\n",
    "dfCSV = np.genfromtxt('/home/debora/Desktop/MoCapRasp/server/data/camTest.csv', delimiter=',')\n",
    "recTime = 60     # recording time, in seconds\n",
    "step = 1/100     # step of the interpolated DF\n",
    "isDrone = False  # should I realign the point cloud to match the drones X and Y axis\n",
    "\n",
    "# flags\n",
    "saveDF = False                 # save dataframe \n",
    "whichCamera = ''               # save which camera\n",
    "correctDF = False              # use correction matrices\n",
    "refineCorrection = False       # refine correction matrices\n",
    "saveFolder = '/home/debora/Desktop/MoCapRasp/server/data/'  # folder where to save DF\n",
    "correctionFolder = '/home/debora/Desktop/MoCapRasp/server/data/'   # folder where to catch data to correction amtrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction matrices\n",
    "\n",
    "Since **there are errors in the focal distance** calibration, there will be errors when matching the clouds from different pairs of camera. But we can compute the rotation and translation from each point cloud to the point cloud of the pair 0-1. \n",
    "\n",
    "**This correctio is done on a test dataset. Use the flags above to configure the algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if correctDF:\n",
    "    # read CSV\n",
    "    dfTriang_12 = np.genfromtxt(correctionFolder+'dfTriang_12.csv', delimiter=',')\n",
    "    dfTriang_23 = np.genfromtxt(correctionFolder+'dfTriang_23.csv', delimiter=',')\n",
    "    dfTriang_34 = np.genfromtxt(correctionFolder+'dfTriang_34.csv', delimiter=',')\n",
    "\n",
    "    # create all pairs dataset\n",
    "    correcMat,allPermut = [],np.array(list(permutations(list(range(nCameras)))))\n",
    "    dfTriang = np.zeros((int(recTime/step),(nCameras-1)*16+1))\n",
    "    dfTriang[:,-1] = np.arange(0,recTime,step)\n",
    "    dfTriang[np.around(dfTriang_12[:,-1]*100).astype(int),0:16] = dfTriang_12[:,:-1]\n",
    "    dfTriang[np.around(dfTriang_23[:,-1]*100).astype(int),16:32] = dfTriang_23[:,:-1]\n",
    "    dfTriang[np.around(dfTriang_34[:,-1]*100).astype(int),32:48] = dfTriang_34[:,:-1]\n",
    "\n",
    "    # minimize pair 1 and 2\n",
    "    emptyLines = np.unique([i for i in range(0,dfTriang.shape[0]) for k in [0,1] if not dfTriang[i][k*16]])\n",
    "    #emptyLines = np.unique(np.hstack((emptyLines,list(range(0,2000)))))\n",
    "    dfMinimize = np.delete(dfTriang,emptyLines,axis=0)\n",
    "    for i in range(dfMinimize.shape[0]):\n",
    "        ptsA,ptsB =  dfMinimize[i,0:16].reshape(-1,4).T,dfMinimize[i,16:32].reshape(-1,4).T\n",
    "        allDists = []\n",
    "        for order in allPermut:\n",
    "            aux = ptsB[:,order]\n",
    "            allDists.append(np.sum(np.linalg.norm(ptsA-aux,axis=0))  )\n",
    "        order = allPermut[np.argmin(allDists)]\n",
    "        #print(order,min(allDists))\n",
    "        dfMinimize[i,16:32] = ptsB[:,order].T.reshape(-1,16)\n",
    "    ptsA = dfMinimize[:,0:16].reshape(-1,4).T\n",
    "    ptsB = dfMinimize[:,16:32].reshape(-1,4).T\n",
    "    ptA,ptB = np.copy(ptsB[0:3]), np.copy(ptsA[0:3])    \n",
    "    R,t = findRandT(ptA,ptB)\n",
    "    P = np.vstack((np.hstack((R,t.reshape(-1,1))),np.hstack((np.zeros((3)),1))))\n",
    "    correcMat.append(P)\n",
    "    points3d = np.matmul(P,ptsB)\n",
    "    error,deleteIdx = np.linalg.norm(points3d - ptsA,axis=0)*100,[]\n",
    "    if refineCorrection:\n",
    "        for i in range(1,len(error)):\n",
    "            if abs(error[i]-np.mean(error)) > 3*np.std(error) : deleteIdx.append(int(i/4))\n",
    "        if len(deleteIdx):\n",
    "            dfMinimize = np.delete(dfMinimize,np.unique(deleteIdx),axis=0)\n",
    "            ptsA = dfMinimize[:,0:16].reshape(-1,4).T\n",
    "            ptsB = dfMinimize[:,16:32].reshape(-1,4).T\n",
    "            ptA,ptB = np.copy(ptsB[0:3]), np.copy(ptsA[0:3])\n",
    "            R,t = findRandT(ptA,ptB)\n",
    "            P = np.vstack((np.hstack((R,t.reshape(-1,1))),np.hstack((np.zeros((3)),1))))\n",
    "            correcMat.append(P)\n",
    "            points3d = np.matmul(P,ptsB)\n",
    "            error = np.linalg.norm(points3d - ptsA,axis=0)*100\n",
    "    print('## Pair 1-2 and 2-3 ##')\n",
    "    print('Using '+str(int(ptsA.shape[1]/4))+' images')\n",
    "    print('min. error:', round(min(error),2),' cm')\n",
    "    print('max. error:', round(max(error),2),' cm')\n",
    "    print('mean error:', round(np.mean(error),2),' cm')\n",
    "    print('std. dev. error:', round(np.std(error),2),' cm')\n",
    "    plt.plot(error)    \n",
    "    #np.savetxt(correctionFolder+'dfMinimize_12.csv',dfMinimize,delimiter=',')\n",
    "\n",
    "    # minimize pair 1 and 3\n",
    "    emptyLines = np.unique([i for i in range(0,dfTriang.shape[0]) for k in [0,2] if not dfTriang[i][k*16]])\n",
    "    #emptyLines = np.unique(np.hstack((emptyLines,list(range(0,2000)))))\n",
    "    dfMinimize = np.delete(dfTriang,emptyLines,axis=0)\n",
    "    for i in range(dfMinimize.shape[0]):\n",
    "        ptsA,ptsB =  dfMinimize[i,0:16].reshape(-1,4).T,dfMinimize[i,32:48].reshape(-1,4).T\n",
    "        allDists = []\n",
    "        for order in allPermut:\n",
    "            aux = ptsB[:,order]\n",
    "            allDists.append(np.sum(np.linalg.norm(ptsA-aux,axis=0))  )\n",
    "        order = allPermut[np.argmin(allDists)]\n",
    "        #print(order,min(allDists))\n",
    "        dfMinimize[i,32:48] = ptsB[:,order].T.reshape(-1,16)\n",
    "    ptsA = dfMinimize[:,0:16].reshape(-1,4).T\n",
    "    ptsB = dfMinimize[:,32:48].reshape(-1,4).T\n",
    "    ptA,ptB = np.copy(ptsB[0:3]), np.copy(ptsA[0:3])\n",
    "    R,t = findRandT(ptA,ptB)\n",
    "    P = np.vstack((np.hstack((R,t.reshape(-1,1))),np.hstack((np.zeros((3)),1))))\n",
    "    correcMat.append(P)\n",
    "    points3d = np.matmul(P,ptsB)\n",
    "    error,deleteIdx = np.linalg.norm(points3d - ptsA,axis=0)*100,[]  \n",
    "    if refineCorrection:\n",
    "        for i in range(1,len(error)):\n",
    "            if abs(error[i]-np.mean(error)) > 3*np.std(error) : deleteIdx.append(int(i/4))\n",
    "        if len(deleteIdx):\n",
    "            dfMinimize = np.delete(dfMinimize,np.unique(deleteIdx),axis=0)\n",
    "            ptsA = dfMinimize[:,0:16].reshape(-1,4).T\n",
    "            ptsB = dfMinimize[:,32:48].reshape(-1,4).T\n",
    "            ptA,ptB = np.copy(ptsB[0:3]), np.copy(ptsA[0:3])\n",
    "            R,t = findRandT(ptA,ptB)\n",
    "            P = np.vstack((np.hstack((R,t.reshape(-1,1))),np.hstack((np.zeros((3)),1))))\n",
    "            correcMat.append(P)\n",
    "            points3d = np.matmul(P,ptsB)\n",
    "            error = np.linalg.norm(points3d - ptsA,axis=0)*100\n",
    "    print('\\n## Pair 1-2 and 3-4 ##')\n",
    "    print('Using '+str(int(ptsA.shape[1]/4))+' images')\n",
    "    print('min. error:', round(min(error),2),' cm')\n",
    "    print('max. error:', round(max(error),2),' cm')\n",
    "    print('mean error:', round(np.mean(error),2),' cm')\n",
    "    print('std. dev. error:', round(np.std(error),2),' cm')\n",
    "    plt.plot(error) \n",
    "    #np.savetxt(correctionFolder+'dfMinimize_13.csv',dfMinimize,delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading coordinates, ordering and triangulating markers\n",
    "\n",
    "Now we do ordering and triangulation inside the reading loop. The epiline approach for ordering tests 16 possibilities at each loop, so we keep track of the camera pairs that needs ordering of the centroids. When at least one image is ordered, the blobs in following ones are tracked by proximity. The reference is reset if more than 10 images are invalid (per time missmatch or occlusion)\n",
    "\n",
    "Nevertheless, we can only relate the two cameras when all four markers are visible at the same time. We do as following:\n",
    "\n",
    "- Wait for the cameras to have at least 3 images in storage for the actual valid interval.\n",
    "- Check which cameras still need to be related to the one that sent the last package.\n",
    "- If yes, check if valid time interval of this other camera has intesection with that camera that sent the last package.\n",
    "- If yes, we order the blobs at the first intersection timestamp per epipolar line.\n",
    "- Then we flip the blobs according to this order on the second camera (sorted by index) in the non interpolated database since the beggining fo the actual valid time interval.\n",
    "- We notify that any camera index comming after this second camera index also needs reordering when the next package is received.\n",
    "\n",
    "Then, for triangulation, we follow as:\n",
    "\n",
    "- Wait for the cameras to have at least 10 images in storage for the actual valid interval to start triangulating\n",
    "- Interpolate the blobs that have not been already interpolated.\n",
    "- Check if any of the interpolated images are also seen by any other camera (always neighbours).\n",
    "- Triangulate markers with this camera (including projection matrix, ground plane rotation and correction matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nMarkers = 4\n",
    "\n",
    "# initiating empty arrays\n",
    "counter,i,lastTime = np.zeros(nCameras,dtype=np.int32),0,np.zeros(nCameras,dtype=np.int32)\n",
    "missed,invalid,swap = np.zeros(nCameras,dtype=np.int32),np.zeros(nCameras,dtype=np.int32),np.zeros(nCameras,dtype=np.int32)\n",
    "lastImgNumber = np.zeros(nCameras,dtype=np.int32)\n",
    "intervals,lastTnew = [],[]\n",
    "\n",
    "# warmUp = number of images in storage for the actual valid interval to start triangulating\n",
    "# nPrevious = number of images in camera storage for the actual valid interval\n",
    "dfOrig,nPrevious,warmUp = [],3,10 # warm up > n previous \n",
    "\n",
    "needsOrder = createNeedsOrder(nCameras,relateLast2First=0)\n",
    "\n",
    "allPoints3d = [] # List of all 3D points in the whole footage\n",
    "\n",
    "verbose = False # Verbose Info\n",
    "\n",
    "for _ in range(nCameras): # For each camera\n",
    "    dfOrig.append([]) # List for each camera\n",
    "    intervals.append([]) # List for each camera\n",
    "    lastTnew.append([]) # List for each camera\n",
    "\n",
    "# Each PTS will have a 2D marker coordinate for each camera + 2 additional columns\n",
    "dfInterp = np.zeros((int(recTime/step),nCameras*(2*nMarkers)+2)) # Last two columns are special\n",
    "\n",
    "dfInterp[:,-2] = np.arange(0,recTime,step) # Penultimate column is filled with the time stamps\n",
    "dfInterp[:,-1] = np.zeros_like(dfInterp[:,-1],dtype=np.bool8) # Last column is filled with bool zeros (false)\n",
    "\n",
    "# Each PTS will have...\n",
    "dfTriang = np.zeros((int(recTime/step),(4*nMarkers)+1)) # 4D coordinates of each marker + PTS\n",
    "dfTriang[:,-1] = np.arange(0,recTime,step) # Last column is filled with the PTSs\n",
    "\n",
    "timeArray = []\n",
    "otherCamera = findOtherCamera(whichCamera,nCameras)\n",
    "\n",
    "# Test loop done in real time\n",
    "while i != dfCSV.shape[0]: # Capture frames\n",
    "    start = time.time() # Just to measure loop time\n",
    "    line = dfCSV[i] # Current frame info\n",
    "    # Get data from the line\n",
    "    # Lines are: 2D Coordinates from each marker | Current time | Image number | Camera Index\n",
    "    undCoord,timeNow,imgNumber, idx = line[0:(2*nMarkers)].reshape(-1,2), line[-3], line[-2], int(line[-1])\n",
    "\n",
    "    i += 1 # Update to next frame for next iteration\n",
    "\n",
    "    if len(otherCamera): # If there is camera available in otherCamera\n",
    "        if idx in otherCamera: continue # If Camera is in otherCamera\n",
    "\n",
    "    # Time missmatch\n",
    "    if counter[idx]:\n",
    "        if abs(timeNow-lastTime[idx])>1e9: \n",
    "            if verbose: print('time missmatch')\n",
    "            missed[idx] += 1 # One more missed image for the camera\n",
    "            invalid[idx] += 1 # One more invalid image for the camera\n",
    "            continue\n",
    "    \n",
    "    # Check if sequence is valid\n",
    "    if imgNumber > lastImgNumber[idx] + 1: invalid[idx] = imgNumber-lastImgNumber[idx]\n",
    "\n",
    "    # Check occlusion and order markers per proximity\n",
    "    if not occlusion(undCoord,5) and not np.any(undCoord<0): \n",
    "        if invalid[idx]>=10 or not counter[idx]: \n",
    "            if verbose: print('reseting at camera', idx,', counter',counter[idx],',',timeNow/1e6,'s')\n",
    "            prev,needsOrder = [],activateNeedsOrder(nCameras,idx,needsOrder,relateLast2First=0)\n",
    "            intervals[idx].append(counter[idx])\n",
    "        else:\n",
    "            if not (counter[idx]-1): prev = np.array(dfOrig[idx][0:(2*nMarkers)]).reshape(-1,2)\n",
    "            else: prev = np.array(dfOrig[idx][-1,0:(2*nMarkers)]).reshape(-1,2)\n",
    "            newOrder = getTheClosest(undCoord.reshape(-1,2),prev.reshape(-1,2))\n",
    "            undCoord = np.copy(undCoord[newOrder])\n",
    "    else: \n",
    "        if verbose: print('not collinear or equal centroids')\n",
    "        missed[idx] += 1 # One more missed image for the camera\n",
    "        invalid[idx] += 1 # One more invalid image for the camera\n",
    "        continue\n",
    "\n",
    "    # Update loop variables\n",
    "    lastTime[idx],lastImgNumber[idx],invalid[idx] = timeNow,imgNumber,0    \n",
    "    if not counter[idx]: dfOrig[idx] = np.hstack((undCoord.reshape(2*nMarkers),timeNow))\n",
    "    else: dfOrig[idx] = np.vstack((dfOrig[idx],np.hstack((undCoord.reshape(2*nMarkers),timeNow))))\n",
    "    counter[idx] += 1\n",
    "\n",
    "    # Interpolate\n",
    "    if needsOrder[str(idx)].size:\n",
    "        # Get if there are enough points at the valid interval\n",
    "        for otherIdx in needsOrder[str(idx)]:\n",
    "            if not len(intervals[otherIdx]): continue\n",
    "            myCounter,myIntervals = np.array([counter[idx],counter[otherIdx]]),np.array([intervals[idx][-1],intervals[otherIdx][-1]])            \n",
    "            if np.all(myCounter-myIntervals>=nPrevious):\n",
    "                # see if there are intersection between arrays\n",
    "                ts1,ts2 = dfOrig[idx][intervals[idx][-1]:counter[idx],(2*nMarkers)]/1e6,dfOrig[otherIdx][intervals[otherIdx][-1]:counter[otherIdx],(2*nMarkers)]/1e6\n",
    "                validIdx1 = [k for k in range(0,len(ts1)) if max(ts1[0], ts2[0])-0.01<=ts1[k]<=min(ts1[-1], ts2[-1])+0.01]\n",
    "                validIdx2 = [k for k in range(0,len(ts2)) if max(ts1[0], ts2[0])-0.01<=ts2[k]<=min(ts1[-1], ts2[-1])+0.01]\n",
    "                # if there is intersection, get order\n",
    "                if len(validIdx1) and len(validIdx2):\n",
    "                    ts1,ts2 = np.copy(ts1[validIdx1]),np.copy(ts2[validIdx2])\n",
    "                    if ts1.shape[0]<2 or ts2.shape[0]<2: continue\n",
    "                    coord1,coord2 = dfOrig[idx][intervals[idx][-1]:counter[idx],0:(2*nMarkers)],dfOrig[otherIdx][intervals[otherIdx][-1]:counter[otherIdx],0:(2*nMarkers)]\n",
    "                    coord1,coord2 = np.copy(coord1[validIdx1]),np.copy(coord2[validIdx2])\n",
    "                    # Get interpolated data\n",
    "                    interp1,tNew1 = myInterpolate(coord1,ts1,step)\n",
    "                    interp2,tNew2 = myInterpolate(coord2,ts2,step)\n",
    "                    if not len(interp1) or not len(interp2): continue\n",
    "                    # Get min and max idx\n",
    "                    minIdx,maxIdx = min(idx,otherIdx),max(idx,otherIdx)\n",
    "                    # Get common idx\n",
    "                    F = FMatrix[minIdx]\n",
    "                    interpolateIdx1,interpolateIdx2 = np.argmax(np.in1d(tNew1, tNew2)),np.argmax(np.in1d(tNew2, tNew1))\n",
    "                    # Order per epipolar line\n",
    "                    if idx < otherIdx: orderSecondFrame,ret = getOrderPerEpiline(interp1[-1],interp2[-1],nMarkers,F,0,1)\n",
    "                    else: orderSecondFrame,ret = getOrderPerEpiline(interp2[-1],interp1[-1],nMarkers,F,0,1)\n",
    "                    if not ret: \n",
    "                        if verbose: print(minIdx,maxIdx,'could not rearange at',tNew2[-1]*step,'s')\n",
    "                        continue\n",
    "                    # Get interval to rearrange\n",
    "                    if verbose: print(minIdx,maxIdx,'rearanging interval',[intervals[maxIdx][-1],counter[maxIdx]], 'to', orderSecondFrame, 'at',tNew2[-1]*step,'s')\n",
    "                    # Flip blobs\n",
    "                    for k in range(intervals[maxIdx][-1],counter[maxIdx]):\n",
    "                       dfOrig[maxIdx][k,0:(2*nMarkers)] = np.copy(dfOrig[maxIdx][k,0:(2*nMarkers)].reshape(-1,2)[orderSecondFrame].reshape(-(2*nMarkers)))\n",
    "                    # Change ordering boolean\n",
    "                    needsOrder=popNeedsOrder(idx,otherIdx,needsOrder)\n",
    "                    for k in range(maxIdx+1,nCameras):\n",
    "                        needsOrder=activateNeedsOrder(nCameras,k,needsOrder,relateLast2First=0) \n",
    "\n",
    "    if (counter[idx]-intervals[idx][-1]) >= warmUp: \n",
    "        # Get data to interpolate\n",
    "        coord,ts = dfOrig[idx][(counter[idx]-warmUp):counter[idx],0:(2*nMarkers)],dfOrig[idx][(counter[idx]-warmUp):counter[idx],(2*nMarkers)]/1e6\n",
    "        if not len(ts): continue\n",
    "        lowBound,highBound = math.ceil(ts[0]/step),math.floor(ts[-1]/step)\n",
    "        # Avoid repeating intepolation\n",
    "        if lastTnew[idx]:\n",
    "            if lowBound<lastTnew[idx]: lowBound = lastTnew[idx]+1\n",
    "        # Interpolate\n",
    "        tNew = np.linspace(lowBound,highBound,int((highBound-lowBound))+1,dtype=np.uint16)\n",
    "        ff = CubicSpline(ts,coord,axis=0)\n",
    "        # Save data\n",
    "        dfInterp[tNew,int(idx*(2*nMarkers)):int(idx*(2*nMarkers)+(2*nMarkers))] = ff(tNew*step)\n",
    "        lastTnew[idx] = tNew[-1]\n",
    "        # Compare if there is another camera available\n",
    "        for k in tNew:\n",
    "            if dfInterp[k,-1]: continue\n",
    "            otherIdx = getOtherValidIdx(dfInterp[k,:],nMarkers,idx)      \n",
    "            if not len(otherIdx) or otherIdx in needsOrder[str(idx)]: continue      \n",
    "            # Get index from the other camera\n",
    "            dfInterp[k,-1],otherIdx = True,otherIdx[0]\n",
    "            # Comparing the indexes to set the projection matrices\n",
    "            minIdx,maxIdx = min(idx,otherIdx),max(idx,otherIdx)\n",
    "            # Getting the data\n",
    "            pts1,pts2 = dfInterp[k,minIdx*(2*nMarkers):(minIdx+1)*(2*nMarkers)].reshape(-1,2),dfInterp[k,maxIdx*(2*nMarkers):(maxIdx+1)*(2*nMarkers)].reshape(-1,2)\n",
    "            R,t,lamb = rotation[maxIdx],translation[maxIdx].reshape(-1,3),scale[maxIdx]\n",
    "            P1,P2 = np.hstack((cameraMat[minIdx], [[0.], [0.], [0.]])),np.matmul(cameraMat[maxIdx], np.hstack((R, t.T)))\n",
    "            projPt1,projPt2 = myProjectionPoints(np.array(pts1)),myProjectionPoints(np.array(pts2))\n",
    "            # Triangulate\n",
    "            points4d = triangulatePoints(P1.astype(float),P2.astype(float),projPt1.astype(float),projPt2.astype(float))\n",
    "            points3d = (points4d[:3, :]/points4d[3, :]).T\n",
    "            if points3d[0, 2] < 0: points3d = -points3d  \n",
    "            # Project in scale regarding the minimum index camera\n",
    "            points3d = np.hstack((points3d*lamb/100,np.ones((points3d.shape[0],1)))).T\n",
    "            points3d = np.matmul(projMat[minIdx],points3d).T\n",
    "            # Rotate to ground plane\n",
    "            points3d += [0,d/b,0,0]\n",
    "            points3d = np.matmul(P_plane,points3d.T).T\n",
    "            points3d += [0,0,-zDisplacement,0]\n",
    "            \n",
    "            # Save to array\n",
    "            dfTriang[k,0:(4*nMarkers)] = np.copy(points3d.ravel()) \n",
    "            if not len(allPoints3d): allPoints3d = np.copy(points3d)\n",
    "            else: allPoints3d = np.vstack((allPoints3d,np.copy(points3d))) \n",
    "\n",
    "    timeArray.append(time.time()-start)\n",
    "\n",
    "# just comprising dataset if wanted to plot\n",
    "emptyLines = np.unique([i for i in range(0,dfInterp.shape[0]) if not dfInterp[i][-1]])\n",
    "dfInterp = np.delete(dfInterp,emptyLines,axis=0)\n",
    "dfTriang = np.delete(dfTriang,emptyLines,axis=0)\n",
    "print('[INFO] found ' +str(dfTriang.shape[0])+ ' interpolated pics')\n",
    "# time plot for further temporal analysis\n",
    "print('[INFO] Temporal analysis')\n",
    "print('\\t> Min:',round(np.min(timeArray),5),'s')\n",
    "print('\\t> Mean:',round(np.mean(timeArray),5),'s')\n",
    "print('\\t> Max:',round(np.max(timeArray),5),'s')\n",
    "print('\\t> Std. Dev.:',round(np.std(timeArray),5),'s')\n",
    "allPoints3d = np.array(allPoints3d).T\n",
    "# save dataset\n",
    "if saveDF:\n",
    "    name = 'dfTriang_'\n",
    "    if len(whichCamera): name += whichCamera\n",
    "    else: name += 'Mix'\n",
    "    if correctDF: name += '_corrected'\n",
    "    np.savetxt(saveFolder+name+'.csv',dfTriang,delimiter=',')\n",
    "\n",
    "# plot debug for interpolated dataset\n",
    "'''for idx in range(nCameras):\n",
    "    os.system('del -rf pics\\cam'+str(idx+1)+'\\*jpg')\n",
    "    for j in range(0,dfInterp.shape[0]):\n",
    "        pts,name,img,k = dfInterp[j,int(idx*8):int(idx*8+8)].reshape(-1,2),int(dfInterp[j,-2]/step),np.ones((720,960,3))*255,0\n",
    "        for k in range(0,4):\n",
    "            pt = pts.reshape(-1,2)[k]\n",
    "            center = (int(np.round(pt[0]*16)),int(np.round(pt[1]*16)))\n",
    "            circle(img,center,10,(255,0,0),5,shift=4)\n",
    "            putText(img,str(k),(int(center[0]/16)-25, int(center[1]/16)-25),FONT_HERSHEY_SIMPLEX,0.5,(255,0,0),2) \n",
    "        imwrite('pics/cam'+str(idx+1)+'/'+str(name).zfill(20)+'.jpg',img)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual plot and anaylisis\n",
    "\n",
    "The following cells plot the 3D mat and 2D analysis of the data captured during the test live loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 3D plot variables\n",
    "fig = plt.figure(figsize=(8, 8),dpi=100)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlim(-1, 4)\n",
    "ax.set_zlim(-6, 0)\n",
    "ax.set_ylim(-1, 4)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Z')\n",
    "ax.set_zlabel('Y')\n",
    "ax.set_xlabel('X', fontweight='bold',labelpad=15)\n",
    "ax.set_ylabel('Z', fontweight='bold',labelpad=15)\n",
    "ax.set_zlabel('Y', fontweight='bold',labelpad=5)\n",
    "cmhot = plt.get_cmap(\"jet\")\n",
    "ax.view_init(elev=30, azim=-50) \n",
    "plt.gca().invert_zaxis()\n",
    "ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([1., 1., .5, 1.]))\n",
    "colours = [['fuchsia','plum'],['darkorange','gold'],['limegreen','greenyellow'],['blue','lightsteelblue']]\n",
    "\n",
    "# plot each camera translated and rotated to meet the ground plane\n",
    "for j in range(nCameras):\n",
    "    o = np.matmul(projMat[j],[[0.],[0],[0.],[1]]).ravel()\n",
    "    o+= [0,+d/b,0,0]\n",
    "    o = np.matmul(P_plane,o).ravel()\n",
    "    o+= [0,0,-zDisplacement,0]\n",
    "    x,y,z= np.array([1, 0, 0, 0]), np.array([0, 1, 0, 0]),np.array([0, 0, 1, 0])\n",
    "    x,y,z = np.matmul(projMat[j],x),np.matmul(projMat[j],y),np.matmul(projMat[j],z)\n",
    "    x,y,z = np.matmul(P_plane,x),np.matmul(P_plane,y),np.matmul(P_plane,z)\n",
    "    ax.quiver(o[0], o[2], o[1], x[0], x[2], x[1], arrow_length_ratio=0.1, edgecolors=\"r\", label='X axis')\n",
    "    ax.quiver(o[0], o[2], o[1], y[0], y[2], y[1], arrow_length_ratio=0.1, edgecolors=\"b\", label='Y axis')\n",
    "    ax.quiver(o[0], o[2], o[1], z[0], z[2], z[1], arrow_length_ratio=0.1, edgecolors=\"g\", label='Z axis')\n",
    "    ax.scatter(o[0], o[2], o[1], s=50, edgecolor=colours[j][0], facecolor=colours[j][1], linewidth=2,  label = 'Camera '+str(j))\n",
    "\n",
    "# plot points after correction matrix\n",
    "ax.scatter(allPoints3d[0], allPoints3d[2], allPoints3d[1], s=50, c=allPoints3d[2], cmap=cmhot, label= 'Markers')\n",
    "\n",
    "# axis setup and plot variables\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys(),ncol=3,loc ='center',edgecolor='silver', bbox_to_anchor=(0.5, 0.8))\n",
    "plt.draw()\n",
    "plt.show()\n",
    "\n",
    "# save array of each point for later use (e.g. Matlab)\n",
    "for k in range(0,4):\n",
    "    idx = np.array(range(k,allPoints3d.shape[1],4)).astype(int)\n",
    "    points3dNew = allPoints3d.T[idx]\n",
    "    #np.savetxt('data/points3d'+str(k)+'.csv',points3dNew,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotating the point cloud and ploting\n",
    "\n",
    "If we captured data of a drone, we can find the two markers on the front propellers and realign the X and Y axis to match the inertial body frame of the first drone position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isDrone:\n",
    "    #variable initialization\n",
    "    allCombinationsOf2 = np.array(list(combinations(list(range(0,4)),2)))\n",
    "    myNorm = []\n",
    "    # get first position\n",
    "    pts = dfTriang[0,0:-1].reshape(-1,4)[:,0:3]\n",
    "    print(pts)\n",
    "    for idx in allCombinationsOf2:\n",
    "        myNorm.append(np.linalg.norm(np.diff(pts[idx],axis=0)))\n",
    "    # The farthest apert are the vertices A and C\n",
    "    orderedNorm = np.argsort(myNorm)\n",
    "    extremitiesIdx = allCombinationsOf2[orderedNorm[-1]]\n",
    "    # add the non aligned marker\n",
    "    allVertices = np.unique([allCombinationsOf2[orderedNorm[-1]],allCombinationsOf2[orderedNorm[-2]]])\n",
    "    # find the non aligned marker index\n",
    "    rightAngleIdx = allVertices[np.argmin(np.in1d(allVertices,extremitiesIdx))]\n",
    "    # find the middle marker and atribute it as origin\n",
    "    middleIdx = np.array([0,1,2,3])[np.argmin(np.in1d(np.array([0,1,2,3]),allVertices))]\n",
    "    newO = pts[middleIdx].copy()\n",
    "    # rotate the points so the the vector between the middle marker and the non aligned marker is the X axis\n",
    "    transPts = pts-pts[middleIdx]\n",
    "    v = (transPts[rightAngleIdx])\n",
    "    k = np.array([1,0,0])*.15\n",
    "    cosPhi = np.dot(v,k)/(np.linalg.norm(v)*np.linalg.norm(k))\n",
    "    [u1,u2,u3] = np.cross(v,k)/np.linalg.norm(np.cross(v,k))\n",
    "    sinPhi = np.sqrt(1-pow(cosPhi,2))\n",
    "    R1 = np.array([\n",
    "            [cosPhi+u1*u1*(1-cosPhi),u1*u2*(1-cosPhi)-u3*sinPhi,u2*sinPhi+u1*u3*(1-cosPhi)],\n",
    "            [u1*u2*(1-cosPhi)+u3*sinPhi,cosPhi+u2*u2*(1-cosPhi),u2*u3*(1-cosPhi)-u1*sinPhi],\n",
    "            [u1*u3*(1-cosPhi)-u2*sinPhi,u2*u3*(1-cosPhi)+u1*sinPhi,cosPhi+u3*u3*(1-cosPhi)]])\n",
    "    rotPts = np.matmul(R1,transPts.T).T\n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(8, 8),dpi=100)\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.set_xlim(0.2, 0.8)\n",
    "    ax.set_zlim(-6, 0)\n",
    "    ax.set_ylim(2.8,3.2)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Z')\n",
    "    ax.set_zlabel('Y')\n",
    "    ax.set_xlabel('X', fontweight='bold',labelpad=15)\n",
    "    ax.set_ylabel('Z', fontweight='bold',labelpad=15)\n",
    "    ax.set_zlabel('Y', fontweight='bold',labelpad=5)\n",
    "    cmhot = plt.get_cmap(\"jet\")\n",
    "    ax.view_init(elev=30, azim=-50) \n",
    "    plt.gca().invert_zaxis()\n",
    "    ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([1., 1., .5, 1.]))\n",
    "    colours = [['fuchsia','plum'],['darkorange','gold'],['limegreen','greenyellow'],['blue','lightsteelblue']]\n",
    "    \n",
    "    # find the marker to the right of the X axis\n",
    "    '''vertixIdx = np.argsort(rotPts[:,2])[0]\n",
    "    # find the middle point between the the marker to the right of the X axis and\n",
    "    # the non aligned marker is the X axis\n",
    "    middlePt = (transPts[rightAngleIdx]-transPts[vertixIdx])/2\n",
    "    # rotating around Y axis to align to the middle point projection at Y=0\n",
    "    k = np.array([1,0,0])*.15\n",
    "    v = (middlePt-transPts[middleIdx]).copy()\n",
    "    v[1] = 0\n",
    "    cosPhi = np.dot(v,k)/(np.linalg.norm(v)*np.linalg.norm(k))\n",
    "    [u1,u2,u3] = np.cross(v,k)/np.linalg.norm(np.cross(v,k))\n",
    "    sinPhi = np.sqrt(1-pow(cosPhi,2))\n",
    "    R1 = np.array([\n",
    "            [cosPhi+u1*u1*(1-cosPhi),u1*u2*(1-cosPhi)-u3*sinPhi,u2*sinPhi+u1*u3*(1-cosPhi)],\n",
    "            [u1*u2*(1-cosPhi)+u3*sinPhi,cosPhi+u2*u2*(1-cosPhi),u2*u3*(1-cosPhi)-u1*sinPhi],\n",
    "            [u1*u3*(1-cosPhi)-u2*sinPhi,u2*u3*(1-cosPhi)+u1*sinPhi,cosPhi+u3*u3*(1-cosPhi)]])\n",
    "    rotPts = np.matmul(R1,transPts.T).T\n",
    "    v = np.matmul(R1,v.T).T\n",
    "    middlePt = np.matmul(R1,middlePt.T).T\n",
    "\n",
    "    # save new dataset\n",
    "    allPts = []\n",
    "    for n in range(0,dfTriang.shape[0]):\n",
    "        pts,newPts = dfTriang[n,0:-1].reshape(-1,4)[:,0:3],[]\n",
    "        transPts = pts - newO\n",
    "        rotPts = np.matmul(R1,transPts.T).T\n",
    "        if not len(allPts): allPts = np.array(rotPts)\n",
    "        else: allPts = np.vstack((allPts,np.array(rotPts)))\n",
    "        dfTriang[n,0:-1] = np.hstack((rotPts,np.ones((4,1)))).ravel()\n",
    "    allPts = allPts.T\n",
    "\n",
    "    # save array of each point for later use (e.g. Matlab)\n",
    "    for k in range(0,4):\n",
    "        idx = np.array(range(k,allPts.shape[1],4)).astype(int)\n",
    "        points3dNew = allPts.T[idx]'''\n",
    "        #np.savetxt('data/points3d'+str(k)+'_drone.csv',points3dNew,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# initialize variables\n",
    "allCombinationsOf2 = np.array(list(combinations(list(range(0,4)),2)))\n",
    "points3d_rightTriangle = []\n",
    "points3d_centreOfMass = []\n",
    "deleteIdx = []\n",
    "\n",
    "# get position per axis\n",
    "for k in range(0,dfTriang.shape[0]):\n",
    "    # initialize variables\n",
    "    pts,myNorm,ts = dfTriang[k,0:-1].reshape(-1,4)[:,0:3],[],dfTriang[k,-1]\n",
    "    # get the distance between blobs\n",
    "    for idx in allCombinationsOf2:\n",
    "        myNorm.append(np.linalg.norm(np.diff(pts[idx],axis=0)))\n",
    "    orderedNorm = np.argsort(myNorm)\n",
    "    # the blobs furthest apart are the vertices of the triangle\n",
    "    myIdx = np.unique([allCombinationsOf2[orderedNorm[-1]],allCombinationsOf2[orderedNorm[-2]]])\n",
    "    centreOfMass = [i for i in range(0,4) if i not in myIdx]\n",
    "    # save do array\n",
    "    if not len(points3d_rightTriangle): \n",
    "         points3d_centreOfMass = pts[centreOfMass]\n",
    "         points3d_rightTriangle = pts[myIdx]\n",
    "    else: \n",
    "        points3d_centreOfMass = np.vstack((points3d_centreOfMass,pts[centreOfMass]))\n",
    "        points3d_rightTriangle = np.vstack((points3d_rightTriangle,pts[myIdx]))\n",
    "\n",
    "# plotting variables\n",
    "fig, axs = plt.subplots(1,3,figsize=(24,4),dpi=100)\n",
    "colour = ['r','b','g','y']\n",
    "label = ['Position in X-axis (cm)','Position in Y-axis (cm)','Position in Z-axis (cm)']\n",
    "for k in range(0,3):\n",
    "    axs[k].plot(dfTriang[:,-1],points3d_centreOfMass[:,k]*100,\n",
    "                'o',c=colour[k],linewidth=1)\n",
    "    axs[k].set_xlim((0,recTime))\n",
    "    axs[k].grid(True)\n",
    "    axs[k].set_ylabel(label[k],fontweight='bold',size=14)\n",
    "    axs[k].set_xlabel('Time (s)',fontweight='bold',size=14)\n",
    "    plt.rcParams['xtick.labelsize']=14\n",
    "    plt.rcParams['ytick.labelsize']=14\n",
    "\n",
    "# get orientation\n",
    "myOrientation = []\n",
    "for k in range(0,int(points3d_rightTriangle.shape[0]/3)):\n",
    "    # get the coordinates of the vertices of the triangles\n",
    "    pts = points3d_rightTriangle[k*3:k*3+3]-points3d_centreOfMass[k]\n",
    "    # get orthogonal vector and angles\n",
    "    n = np.cross(pts[1]-pts[0], pts[2]-pts[0])\n",
    "    nNormalised = n / np.linalg.norm(n)\n",
    "    angles = np.rad2deg(np.arcsin(nNormalised))\n",
    "    # save array\n",
    "    if not len(myOrientation): myOrientation = [angles]\n",
    "    else: myOrientation = np.vstack((myOrientation,[angles]))\n",
    "\n",
    "# plotting variables\n",
    "fig, axs = plt.subplots(1,3,figsize=(24,4),dpi=100)\n",
    "colour = ['r','b','g']\n",
    "label = [r'$\\mathbf{\\theta\\;(deg)}$',r'$\\mathbf{\\phi\\;(deg)}$',r'$\\mathbf{\\psi\\;(deg)}$']\n",
    "for k in range(0,3):\n",
    "    axs[k].plot(dfTriang[:,-1],myOrientation[:,k],'o',c=colour[k],linewidth=3)\n",
    "    axs[k].set_xlim((0,recTime))\n",
    "    axs[k].grid(True)\n",
    "    axs[k].set_ylabel(label[k],size=14,labelpad=3)\n",
    "    axs[k].set_xlabel('Time (s)',fontweight='bold',size=14)\n",
    "    plt.rcParams['xtick.labelsize']=14\n",
    "    plt.rcParams['ytick.labelsize']=14\n",
    "\n",
    "# ploting upper and lateral map\n",
    "fig, axs = plt.subplots(1,2,figsize=(16,4),dpi=100)\n",
    "axs[0].plot(points3d_centreOfMass[:,0]*100,points3d_centreOfMass[:,2]*100, 'o',c='orange',linewidth=3,label='trajectory')\n",
    "axs[0].plot(points3d_centreOfMass[1,0]*100,points3d_centreOfMass[1,2]*100, '*',\n",
    "            c='blueviolet',linewidth=3,label='take off', markersize=16)\n",
    "axs[0].plot(points3d_centreOfMass[-1,0]*100,points3d_centreOfMass[-1,2]*100, 'X',\n",
    "            c='green',linewidth=3,label='land', markersize=14)\n",
    "axs[0].grid(True); axs[0].axis('equal')\n",
    "#axs[0].set_xlim((-40,40)); axs[0].set_ylim((-50,10)); \n",
    "axs[0].set_ylabel('Position in Z-axis (cm)',fontweight='bold',size=12)\n",
    "axs[0].set_xlabel('Position in X-axis (cm)',fontweight='bold',size=12)\n",
    "pos = axs[0].get_position()\n",
    "axs[0].set_position([pos.x0, pos.y0, pos.width * 0.8, pos.height])\n",
    "axs[1].plot(points3d_centreOfMass[:,0]*100,-points3d_centreOfMass[:,1]*100, 'o',c='orange',label='Trajectory')\n",
    "axs[1].plot(points3d_centreOfMass[1,0]*100,-points3d_centreOfMass[1,1]*100, '*',\n",
    "            c='blueviolet',linewidth=3,label='Take off', markersize=16)\n",
    "axs[1].plot(points3d_centreOfMass[-1,0]*100,-points3d_centreOfMass[-1,1]*100, 'X',\n",
    "            c='green',linewidth=3,label='Land', markersize=14)\n",
    "axs[1].grid(True);\n",
    "#axs[1].set_xlim((-40,40)); axs[1].set_ylim((-10,110))\n",
    "axs[1].set_ylabel('Position in Y-axis (cm)',fontweight='bold',size=12)\n",
    "axs[1].set_xlabel('Position in X-axis (cm)',fontweight='bold',size=12)\n",
    "pos = axs[1].get_position()\n",
    "axs[1].set_position([pos.x0-pos.x0*0.15, pos.y0, pos.width * 0.8, pos.height])\n",
    "plt.rcParams['xtick.labelsize']=14; plt.rcParams['ytick.labelsize']=14\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels,loc='center right', bbox_to_anchor=(.74, 0.28),fontsize=12,labelspacing=.8)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
